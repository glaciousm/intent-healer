# Intent Healer - User Guide

A comprehensive guide to configuring, integrating, and using the LLM-powered self-healing framework for Selenium + Java + Cucumber tests.

---

## Table of Contents

1. [Overview](#overview)
2. [Prerequisites](#prerequisites)
3. [Quick Start](#quick-start)
4. [Java Agent (Zero-Code Integration)](#java-agent-zero-code-integration)
5. [Configuration](#configuration)
6. [Integration Guide](#integration-guide)
7. [CLI Reference](#cli-reference)
8. [IDE Plugins](#ide-plugins)
9. [Healing Modes & Policies](#healing-modes--policies)
10. [Trust Levels](#trust-levels)
11. [Reports & Monitoring](#reports--monitoring)
12. [Troubleshooting](#troubleshooting)
13. [Best Practices](#best-practices)

---

## Overview

Intent Healer is an intelligent self-healing framework that automatically fixes broken element locators in Selenium tests using Large Language Models (LLMs). When a test fails due to a changed UI element, the framework:

1. Captures a snapshot of the current UI state
2. Sends the context to an LLM for analysis
3. Identifies the best matching element
4. Optionally auto-heals and continues the test
5. Logs the healing for review and approval

### Key Features

- **Multiple LLM Providers**: OpenAI, Anthropic, Azure, AWS Bedrock, Ollama (local)
- **Test Framework Integration**: Cucumber, JUnit 5, TestNG
- **Safety Guardrails**: Confidence thresholds, forbidden actions, cost limits
- **Trust Level System**: Progressive automation based on track record
- **IDE Plugins**: IntelliJ IDEA and VS Code support
- **Comprehensive Reporting**: JSON and HTML reports with screenshots

---

## Prerequisites

### Required

- **Java 21+** (LTS recommended)
- **Maven 3.8+** or Gradle 8.x
- **Selenium WebDriver 4.x**
- **Browser** with matching WebDriver (Chrome, Firefox, Edge, etc.)

### Optional (for AI-powered healing)

LLM provider access improves healing accuracy but is **not required**. You can start with the built-in `mock` provider (heuristic-based) which needs no API keys:

- **OpenAI** - API key from platform.openai.com
- **Anthropic** - API key from console.anthropic.com
- **Azure OpenAI** - Deployment from Azure portal
- **AWS Bedrock** - AWS account with Bedrock access
- **Ollama** - Local installation (free, no API key needed)

### Recommended

- IDE with plugin support (IntelliJ IDEA or VS Code)
- Git for version control

---

## Quick Start

This section shows you how to integrate Intent Healer into your existing Selenium project in 5 minutes.

### Step 1: Add Dependencies

**Maven (pom.xml)** - Add these dependencies:

```xml
<dependencies>
    <!-- Intent Healer Core (required) -->
    <dependency>
        <groupId>io.github.glaciousm</groupId>
        <artifactId>healer-core</artifactId>
        <version>1.0.3</version>
        <scope>test</scope>
    </dependency>

    <!-- Intent Healer Selenium Integration (required) -->
    <dependency>
        <groupId>io.github.glaciousm</groupId>
        <artifactId>healer-selenium</artifactId>
        <version>1.0.3</version>
        <scope>test</scope>
    </dependency>

    <!-- Intent Healer LLM Providers (required for AI healing) -->
    <dependency>
        <groupId>io.github.glaciousm</groupId>
        <artifactId>healer-llm</artifactId>
        <version>1.0.3</version>
        <scope>test</scope>
    </dependency>

    <!-- Optional: Framework-specific integration -->
    <!-- For Cucumber -->
    <dependency>
        <groupId>io.github.glaciousm</groupId>
        <artifactId>healer-cucumber</artifactId>
        <version>1.0.3</version>
        <scope>test</scope>
    </dependency>

    <!-- OR for JUnit 5 -->
    <dependency>
        <groupId>io.github.glaciousm</groupId>
        <artifactId>healer-junit</artifactId>
        <version>1.0.3</version>
        <scope>test</scope>
    </dependency>

    <!-- OR for TestNG -->
    <dependency>
        <groupId>io.github.glaciousm</groupId>
        <artifactId>healer-testng</artifactId>
        <version>1.0.3</version>
        <scope>test</scope>
    </dependency>
</dependencies>
```

**Gradle (build.gradle.kts)**:

```kotlin
dependencies {
    // Required dependencies
    testImplementation("io.github.glaciousm:healer-core:1.0.0")
    testImplementation("io.github.glaciousm:healer-selenium:1.0.0")
    testImplementation("io.github.glaciousm:healer-llm:1.0.0")

    // Optional: Choose your test framework integration
    testImplementation("io.github.glaciousm:healer-cucumber:1.0.0")  // For Cucumber
    // OR
    testImplementation("io.github.glaciousm:healer-junit:1.0.0")     // For JUnit 5
    // OR
    testImplementation("io.github.glaciousm:healer-testng:1.0.0")    // For TestNG
}
```

### Step 2: Create Configuration File

Create `healer-config.yml` in `src/test/resources/`:

**Option A: Ollama - Local LLM (recommended)**

```yaml
healer:
  mode: AUTO_SAFE
  enabled: true

  llm:
    provider: ollama
    model: llama3.1
    base_url: http://localhost:11434
    timeout_seconds: 120

  guardrails:
    min_confidence: 0.75
    max_heals_per_scenario: 10

  cache:
    enabled: true
    ttl_hours: 24

  report:
    output_dir: target/healer-reports
    formats:
      - json
      - html
```

> **Prerequisite:** Install Ollama and pull the model first:
> ```bash
> ollama pull llama3.1 && ollama serve
> ```

**Option B: Mock - No LLM (for quick demos)**

```yaml
healer:
  mode: AUTO_SAFE
  enabled: true

  llm:
    provider: mock           # Uses heuristic matching - no LLM needed
    model: heuristic
    timeout_seconds: 30

  guardrails:
    min_confidence: 0.70
    max_heals_per_scenario: 10

  cache:
    enabled: true
    ttl_hours: 24

  report:
    output_dir: target/healer-reports
    formats:
      - json
      - html
```

**Option C: OpenAI - Cloud API (production)**

```yaml
healer:
  mode: AUTO_SAFE
  enabled: true

  llm:
    provider: openai
    model: gpt-4o-mini       # Cost-effective model
    api_key_env: OPENAI_API_KEY
    timeout_seconds: 30
    confidence_threshold: 0.80

  guardrails:
    min_confidence: 0.80
    max_heals_per_scenario: 5

  cache:
    enabled: true
    ttl_hours: 24

  report:
    output_dir: target/healer-reports
    formats:
      - json
      - html
```

### Step 3: Set Up API Key (skip if using mock provider)

If using a cloud LLM provider, set the API key as an environment variable:

```bash
# For OpenAI
export OPENAI_API_KEY="sk-your-api-key-here"

# For Anthropic
export ANTHROPIC_API_KEY="sk-ant-your-key-here"

# For Ollama (local) - no API key needed, just start the server
ollama serve
```

### Step 4: Wrap Your WebDriver

**This is the key integration step.** Replace your regular WebDriver with HealingWebDriver:

```java
import io.github.glaciousm.core.config.ConfigLoader;
import io.github.glaciousm.core.config.HealerConfig;
import io.github.glaciousm.core.engine.HealingEngine;
import io.github.glaciousm.selenium.driver.HealingWebDriver;
import org.openqa.selenium.WebDriver;
import org.openqa.selenium.chrome.ChromeDriver;

public class TestSetup {

    private HealingWebDriver driver;

    public void setUp() {
        // 1. Load Intent Healer configuration
        HealerConfig config = new ConfigLoader().load();

        // 2. Create the healing engine
        HealingEngine engine = new HealingEngine(config);

        // 3. Create your regular WebDriver (any way you prefer)
        WebDriver chromeDriver = new ChromeDriver();

        // 4. Wrap it with HealingWebDriver
        driver = new HealingWebDriver(chromeDriver, engine, config);

        // That's it! Use 'driver' as you normally would
    }

    public void tearDown() {
        if (driver != null) {
            driver.quit();
        }
    }
}
```

### Step 5: Use Your Driver Normally

No changes needed to your test code! Just use the HealingWebDriver like a regular WebDriver:

```java
@Test
public void testLogin() {
    driver.get("https://example.com/login");

    // If this locator breaks, Intent Healer automatically finds the right element
    driver.findElement(By.id("username")).sendKeys("testuser");
    driver.findElement(By.id("password")).sendKeys("password123");
    driver.findElement(By.cssSelector("button[type='submit']")).click();

    // Assertions work normally
    assertTrue(driver.getCurrentUrl().contains("/dashboard"));
}
```

### Step 6: Run Your Tests

```bash
mvn test
```

After the run:
- Check console output for healing summary
- View detailed reports in `target/healer-reports/`
- HTML report shows what was healed with confidence scores

---

## Complete Minimal Example

Here's a complete, copy-paste ready example:

**`src/test/resources/healer-config.yml`**
```yaml
healer:
  mode: AUTO_SAFE
  enabled: true

llm:
  provider: ollama              # Or: mock (no LLM), openai, anthropic
  model: llama3.1
  base_url: http://localhost:11434

cache:
  enabled: true

report:
  output_dir: target/healer-reports
  formats: [html]
```

**`src/test/java/com/example/SelfHealingTest.java`**
```java
package com.example;

import io.github.glaciousm.core.config.ConfigLoader;
import io.github.glaciousm.core.config.HealerConfig;
import io.github.glaciousm.core.engine.HealingEngine;
import io.github.glaciousm.selenium.driver.HealingWebDriver;
import org.junit.jupiter.api.*;
import org.openqa.selenium.By;
import org.openqa.selenium.WebDriver;
import org.openqa.selenium.chrome.ChromeDriver;
import static org.junit.jupiter.api.Assertions.*;

public class SelfHealingTest {

    private static HealingWebDriver driver;
    private static HealingEngine engine;

    @BeforeAll
    static void setupClass() {
        // Load config and create engine once
        HealerConfig config = new ConfigLoader().load();
        engine = new HealingEngine(config);
    }

    @BeforeEach
    void setUp() {
        // Create fresh driver for each test
        HealerConfig config = new ConfigLoader().load();
        WebDriver chromeDriver = new ChromeDriver();
        driver = new HealingWebDriver(chromeDriver, engine, config);
    }

    @AfterEach
    void tearDown() {
        if (driver != null) {
            driver.quit();
        }
    }

    @Test
    void testWithSelfHealing() {
        driver.get("https://the-internet.herokuapp.com/login");

        // These locators work, but if they break, Intent Healer will find alternatives
        driver.findElement(By.id("username")).sendKeys("tomsmith");
        driver.findElement(By.id("password")).sendKeys("SuperSecretPassword!");
        driver.findElement(By.cssSelector("button[type='submit']")).click();

        // Verify login succeeded
        assertTrue(driver.getCurrentUrl().contains("/secure"));
    }
}
```

Run with: `mvn test -Dtest=SelfHealingTest`

---

## LLM Provider Options

Intent Healer supports multiple LLM providers. Choose based on your requirements:

| Provider | API Key Required | Cost | Accuracy | Best For |
|----------|-----------------|------|----------|----------|
| `ollama` | No | Free | Very Good | **Recommended default** - Local development, privacy |
| `mock` | No | Free | Good (heuristic) | Quick demos, CI/CD without LLM |
| `openai` | Yes | ~$0.01/heal | Excellent | Production with cloud AI |
| `anthropic` | Yes | ~$0.01/heal | Excellent | Production with cloud AI |
| `azure` | Yes | ~$0.01/heal | Excellent | Enterprise Azure environments |
| `bedrock` | Yes (AWS) | ~$0.01/heal | Excellent | AWS-based deployments |

### Option 1: Ollama (Local LLM) - Recommended Default

Run AI locally on your machine. No API keys, no costs, full privacy.

**Prerequisites:**
```bash
# Install Ollama
# Windows: winget install Ollama.Ollama
# macOS: brew install ollama
# Linux: curl -fsSL https://ollama.ai/install.sh | sh

# Pull a model (llama3.1 recommended)
ollama pull llama3.1

# Start Ollama server
ollama serve
```

**Complete healer-config.yml:**
```yaml
healer:
  mode: AUTO_SAFE
  enabled: true

llm:
  provider: ollama
  model: llama3.1
  base_url: http://localhost:11434
  timeout_seconds: 120
  max_retries: 2
  temperature: 0.1

guardrails:
  min_confidence: 0.75
  max_heals_per_scenario: 10

cache:
  enabled: true
  ttl_hours: 24

report:
  enabled: true
  output_dir: ./target/healer-reports
  formats:
    - json
    - html
```

**Available Ollama models:**
| Model | Size | Speed | Best For |
|-------|------|-------|----------|
| `llama3.1` | 8B | Medium | General use (recommended) |
| `llama3.1:70b` | 70B | Slow | Complex healing, highest accuracy |
| `mistral` | 7B | Fast | Quick iterations |
| `codellama` | 7B | Fast | Code-heavy tests |
| `phi3` | 3.8B | Very Fast | Resource-constrained environments |

---

### Option 2: Mock Provider (Heuristic-Based)

Uses heuristic matching without any LLM. Good for quick demos or CI/CD pipelines where you don't want LLM dependencies.

**Complete healer-config.yml:**
```yaml
healer:
  mode: AUTO_SAFE
  enabled: true

llm:
  provider: mock
  model: heuristic
  timeout_seconds: 30
  max_retries: 2

guardrails:
  min_confidence: 0.70
  max_heals_per_scenario: 10

cache:
  enabled: true
  ttl_hours: 24

report:
  enabled: true
  output_dir: ./target/healer-reports
  formats:
    - json
    - html
```

**Note:** Mock provider uses attribute matching, text similarity, and DOM position heuristics. It works well for common scenarios but cloud/local LLMs provide better accuracy for complex cases.

---

### Option 3: OpenAI (Cloud API)

Use OpenAI's GPT models for highest accuracy.

**Prerequisites:**
- Get API key from [platform.openai.com](https://platform.openai.com)
- Set environment variable: `export OPENAI_API_KEY=sk-...`

**Complete healer-config.yml:**
```yaml
healer:
  mode: AUTO_SAFE
  enabled: true

llm:
  provider: openai
  model: gpt-4o-mini          # Cost-effective, or gpt-4 for highest accuracy
  api_key_env: OPENAI_API_KEY
  timeout_seconds: 30
  max_retries: 2
  temperature: 0.1
  max_cost_per_run_usd: 5.00

guardrails:
  min_confidence: 0.80
  max_heals_per_scenario: 10

cache:
  enabled: true               # Important: reduces API costs
  ttl_hours: 24

report:
  enabled: true
  output_dir: ./target/healer-reports
  formats:
    - json
    - html
```

**Available OpenAI models:**
| Model | Cost | Speed | Best For |
|-------|------|-------|----------|
| `gpt-4o-mini` | Low | Fast | Daily use (recommended) |
| `gpt-4o` | Medium | Medium | Production |
| `gpt-4` | High | Slow | Highest accuracy |

---

### Option 4: Anthropic (Cloud API)

Use Anthropic's Claude models for excellent reasoning capabilities.

**Prerequisites:**
- Get API key from [console.anthropic.com](https://console.anthropic.com)
- Set environment variable: `export ANTHROPIC_API_KEY=sk-ant-...`

**Complete healer-config.yml:**
```yaml
healer:
  mode: AUTO_SAFE
  enabled: true

llm:
  provider: anthropic
  model: claude-3-haiku-20240307    # Fast and cost-effective
  api_key_env: ANTHROPIC_API_KEY
  timeout_seconds: 30
  max_retries: 2
  temperature: 0.1
  max_cost_per_run_usd: 5.00

guardrails:
  min_confidence: 0.80
  max_heals_per_scenario: 10

cache:
  enabled: true
  ttl_hours: 24

report:
  enabled: true
  output_dir: ./target/healer-reports
  formats:
    - json
    - html
```

**Available Anthropic models:**
| Model | Cost | Speed | Best For |
|-------|------|-------|----------|
| `claude-3-haiku-20240307` | Low | Fast | Daily use (recommended) |
| `claude-3-sonnet-20240229` | Medium | Medium | Production |
| `claude-3-opus-20240229` | High | Slow | Highest accuracy |

---

### Option 5: Azure OpenAI (Enterprise)

For organizations using Azure cloud services.

**Step 1: Get your Azure OpenAI credentials from Azure Portal:**

1. Go to [Azure Portal](https://portal.azure.com) → your Azure OpenAI resource
2. Navigate to **Keys and Endpoint** to find:
   - Endpoint URL (e.g., `https://your-resource.openai.azure.com`)
   - API Key (Key 1 or Key 2)
3. Navigate to **Model deployments** to find your deployment name

**Step 2: Set environment variables:**

```bash
# Required
export AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
export AZURE_OPENAI_API_KEY=your-api-key-here
export AZURE_OPENAI_DEPLOYMENT=your-deployment-name

# Optional (defaults to 2024-02-15-preview)
export AZURE_OPENAI_API_VERSION=2024-02-15-preview
```

**Windows (PowerShell):**
```powershell
$env:AZURE_OPENAI_ENDPOINT = "https://your-resource.openai.azure.com"
$env:AZURE_OPENAI_API_KEY = "your-api-key-here"
$env:AZURE_OPENAI_DEPLOYMENT = "your-deployment-name"
```

**Step 3: Create healer-config.yml:**

```yaml
healer:
  mode: AUTO_SAFE
  enabled: true

llm:
  provider: azure
  model: gpt-4o-mini              # Must match your deployment's model
  timeout_seconds: 30
  max_retries: 2
  temperature: 0.1

guardrails:
  min_confidence: 0.80
  max_heals_per_scenario: 10

cache:
  enabled: true
  ttl_hours: 24

report:
  enabled: true
  output_dir: ./target/healer-reports
  formats:
    - json
    - html
```

> **Note:** The provider reads `AZURE_OPENAI_ENDPOINT`, `AZURE_OPENAI_API_KEY`, and `AZURE_OPENAI_DEPLOYMENT` from environment variables automatically. The `model` in YAML should match the model you deployed (e.g., gpt-4o-mini, gpt-4).

---

### Option 6: AWS Bedrock

For organizations using AWS cloud services.

**Step 1: Enable Bedrock model access in AWS Console:**

1. Go to [AWS Bedrock Console](https://console.aws.amazon.com/bedrock)
2. Navigate to **Model access** → **Manage model access**
3. Enable access to Claude or other models you want to use
4. Wait for access to be granted (usually instant for Claude)

**Step 2: Configure AWS credentials:**

```bash
# Option A: Environment variables
export AWS_ACCESS_KEY_ID=your-access-key
export AWS_SECRET_ACCESS_KEY=your-secret-key
export AWS_REGION=us-east-1

# Option B: AWS credentials file (~/.aws/credentials)
# [default]
# aws_access_key_id = your-access-key
# aws_secret_access_key = your-secret-key

# Option C: IAM role (for EC2/ECS/Lambda - no env vars needed)
```

**Windows (PowerShell):**
```powershell
$env:AWS_ACCESS_KEY_ID = "your-access-key"
$env:AWS_SECRET_ACCESS_KEY = "your-secret-key"
$env:AWS_REGION = "us-east-1"
```

**Step 3: Create healer-config.yml:**

```yaml
healer:
  mode: AUTO_SAFE
  enabled: true

llm:
  provider: bedrock
  model: anthropic.claude-3-haiku-20240307-v1:0
  timeout_seconds: 30
  max_retries: 2
  temperature: 0.1

guardrails:
  min_confidence: 0.80
  max_heals_per_scenario: 10

cache:
  enabled: true
  ttl_hours: 24

report:
  enabled: true
  output_dir: ./target/healer-reports
  formats:
    - json
    - html
```

**Available Bedrock models:**
| Model ID | Description |
|----------|-------------|
| `anthropic.claude-3-haiku-20240307-v1:0` | Fast and cost-effective (recommended) |
| `anthropic.claude-3-sonnet-20240229-v1:0` | Balanced performance |
| `anthropic.claude-3-opus-20240229-v1:0` | Highest accuracy |
| `amazon.titan-text-express-v1` | Amazon's model |

> **Note:** The provider reads AWS credentials from environment variables, `~/.aws/credentials`, or IAM role automatically. Set `AWS_REGION` to your Bedrock region (e.g., us-east-1, us-west-2, eu-west-1).

---

### Fallback Configuration

Configure multiple providers for reliability:

```yaml
llm:
  provider: ollama
  model: llama3.1
  base_url: http://localhost:11434
  timeout_seconds: 120

  # Fallback chain: tried in order if primary fails
  fallback:
    - provider: openai
      model: gpt-4o-mini
      api_key_env: OPENAI_API_KEY
    - provider: anthropic
      model: claude-3-haiku-20240307
      api_key_env: ANTHROPIC_API_KEY
```

---

## Java Agent (Zero-Code Integration)

**The easiest way to add self-healing to your project - no code changes required!**

The Intent Healer Java Agent automatically intercepts all WebDriver instances and adds self-healing capability. Just add a JVM argument and you're done.

### Why Use the Java Agent?

| Approach | Code Changes | Effort | Best For |
|----------|--------------|--------|----------|
| **Java Agent** | None | Minimal | Existing projects, quick setup |
| Manual wrapping | Modify test setup | Medium | Custom control, new projects |

### Step 1: Build or Download the Agent JAR

```bash
# Build from source
mvn clean install -pl healer-agent

# The fat JAR is at: healer-agent/target/healer-agent-1.0.3.jar
```

### Step 2: Create Configuration File

Create `src/test/resources/healer-config.yml`:

```yaml
healer:
  mode: AUTO_SAFE
  enabled: true      # Set to false to disable without removing agent

llm:
  provider: ollama   # Recommended: local LLM (or openai, anthropic, mock)
  model: llama3.1
  base_url: http://localhost:11434
  timeout_seconds: 120

cache:
  enabled: true
  ttl_hours: 24
```

> **Note:** See [LLM Provider Options](#llm-provider-options) for complete configuration examples for each provider.

### Step 3: Add Agent to JVM Arguments

**Option A: Maven Surefire Plugin**

```xml
<plugin>
    <groupId>org.apache.maven.plugins</groupId>
    <artifactId>maven-surefire-plugin</artifactId>
    <configuration>
        <argLine>
            -javaagent:${project.basedir}/../healer-agent/target/healer-agent-1.0.3.jar
        </argLine>
    </configuration>
</plugin>
```

**Option B: Command Line**

```bash
mvn test -DargLine="-javaagent:/path/to/healer-agent-1.0.3.jar"
```

**Option C: Gradle**

```kotlin
test {
    jvmArgs("-javaagent:${rootProject.projectDir}/healer-agent/build/libs/healer-agent-1.0.3.jar")
}
```

**Option D: Direct JVM Execution**

```bash
java -javaagent:healer-agent-1.0.3.jar \
     -jar your-test-runner.jar
```

### Step 4: Run Your Tests

```bash
mvn test
```

When the agent starts, you'll see a banner:

```
+===============================================================+
|           INTENT HEALER AGENT - ACTIVE                        |
+---------------------------------------------------------------+
|  Mode:       AUTO_SAFE                                        |
|  Provider:   ollama                                           |
|  Model:      llama3.1                                         |
|  Healing:    ENABLED                                          |
+===============================================================+

  Self-healing is active for all WebDriver instances.
  Broken locators will be automatically fixed at runtime.
```

### Supported WebDriver Types

The agent automatically intercepts:

- `ChromeDriver`
- `FirefoxDriver`
- `EdgeDriver`
- `SafariDriver`
- `RemoteWebDriver`
- Any custom class extending `RemoteWebDriver`

### Disabling the Agent

**Option 1: Configuration** (recommended)

Set `healer.enabled: false` in `healer-config.yml`

**Option 2: Remove JVM Argument**

Simply remove the `-javaagent` argument from your test configuration.

### Agent vs Manual Integration

The Java Agent approach is best when:
- You want zero code changes to your test project
- You have an existing project with many tests
- You want to quickly evaluate Intent Healer

Use manual HealingWebDriver wrapping when:
- You need fine-grained control over healing
- You want to set custom intent contexts per test
- You're building a new project from scratch

---

## Configuration

### Configuration File Location

The framework searches for configuration in this order:
1. `healer-config.yml` (project root)
2. `healer-config.yaml` (project root)
3. `src/test/resources/healer-config.yml`
4. `.healer/config.yml`

### Complete Configuration Reference

```yaml
# =============================================================================
# HEALER CONFIGURATION
# =============================================================================

healer:
  # Healing mode: OFF, SUGGEST, AUTO_SAFE, AUTO_ALL
  mode: AUTO_SAFE

  # Master switch to enable/disable healing
  enabled: true

# =============================================================================
# LLM PROVIDER CONFIGURATION
# =============================================================================

llm:
  # Provider: openai, anthropic, azure, bedrock, ollama, local
  provider: openai

  # Model name (provider-specific)
  model: gpt-4o-mini

  # Environment variable containing API key
  api_key_env: OPENAI_API_KEY

  # Custom base URL (optional, for proxies or custom endpoints)
  base_url: null

  # Request timeout in seconds
  timeout_seconds: 30

  # Number of retries on failure
  max_retries: 2

  # LLM temperature (lower = more consistent)
  temperature: 0.1

  # Minimum confidence to accept a heal
  confidence_threshold: 0.80

  # Max tokens per LLM request
  max_tokens_per_request: 2000

  # Max LLM requests per test run
  max_requests_per_test_run: 100

  # Cost limit per run (USD)
  max_cost_per_run_usd: 5.00

  # Require LLM to provide reasoning
  require_reasoning: true

  # Fallback providers (tried in order if primary fails)
  fallback:
    - provider: anthropic
      model: claude-3-haiku-20240307
      api_key_env: ANTHROPIC_API_KEY

# =============================================================================
# SAFETY GUARDRAILS
# =============================================================================

guardrails:
  # Minimum confidence score to attempt healing
  min_confidence: 0.80

  # Max heal attempts per failing step
  max_heal_attempts_per_step: 2

  # Max heals allowed per scenario
  max_heals_per_scenario: 5

  # Keywords that prevent healing (element text/attributes)
  forbidden_keywords:
    - delete
    - remove
    - cancel
    - unsubscribe
    - terminate
    - deactivate
    - 削除          # Japanese
    - キャンセル    # Japanese
    - löschen      # German
    - supprimer    # French

  # CSS selectors for error indicators (healing pauses if found)
  error_selectors:
    - ".error-banner"
    - ".alert-danger"
    - ".alert-error"
    - "[role='alert']"
    - ".notification-error"

  # URL patterns where healing is forbidden
  forbidden_url_patterns:
    - "/admin/"
    - "/settings/delete"
    - "/account/close"

  # Allow JavaScript-based clicks (less safe)
  allow_js_click: false

# =============================================================================
# UI SNAPSHOT SETTINGS
# =============================================================================

snapshot:
  # Maximum elements to capture in snapshot
  max_elements: 500

  # Include hidden elements
  include_hidden: false

  # Include disabled elements
  include_disabled: true

  # Capture screenshot with snapshot
  capture_screenshot: true

  # Capture full DOM (increases payload size)
  capture_dom: false

  # Max text length per element
  max_text_length: 200

  # Snapshot capture timeout (ms)
  timeout_ms: 5000

# =============================================================================
# CACHE CONFIGURATION
# =============================================================================

cache:
  # Enable caching of successful heals
  enabled: true

  # Cache time-to-live in hours
  ttl_hours: 24

  # Maximum cache entries
  max_entries: 10000

  # Storage backend: MEMORY, FILE, REDIS
  storage: MEMORY

  # Minimum confidence to cache a heal
  min_confidence_to_cache: 0.70

  # File path for FILE storage
  file_path: .healer/cache

  # Enable persistence (FILE/REDIS only)
  persistence_enabled: true

  # Redis connection URL (REDIS only)
  redis_url: null

# =============================================================================
# REPORT CONFIGURATION
# =============================================================================

report:
  # Output directory for reports
  output_dir: build/healer-reports

  # Generate JSON reports
  json_enabled: true

  # Generate HTML reports
  html_enabled: true

  # Include screenshots in reports
  include_screenshots: true

  # Include LLM prompts (debugging)
  include_llm_prompts: false

  # Include DOM snapshots (large files)
  include_dom_snapshots: false

  # Max artifacts per report
  max_artifacts_per_report: 100

# =============================================================================
# CIRCUIT BREAKER (COST & RELIABILITY PROTECTION)
# =============================================================================

circuit_breaker:
  # Enable circuit breaker
  enabled: true

  # Max false heal rate before circuit opens
  false_heal_rate_threshold: 0.01

  # Window for false heal rate calculation (days)
  false_heal_rate_window_days: 7

  # Minimum samples before rate calculation
  false_heal_rate_min_samples: 20

  # Consecutive failures to open circuit
  consecutive_failures_threshold: 3

  # Successes needed to close circuit
  success_threshold_to_close: 2

  # P95 latency threshold (ms)
  p95_latency_threshold_ms: 10000

  # Latency monitoring window (hours)
  latency_window_hours: 1

  # Daily cost limit (USD)
  daily_cost_limit_usd: 10.00

  # Cooldown period after circuit opens (minutes)
  cooldown_minutes: 30

  # How long circuit stays open (seconds)
  open_duration_seconds: 1800

  # Max attempts in half-open state
  half_open_max_attempts: 3

  # Test heals required in half-open state
  test_heals_required: 3
```

### Auto-Update Configuration

Intent Healer can automatically update your source code when a heal is validated by a passing test. This eliminates repeated healing overhead on subsequent test runs.

```yaml
# =============================================================================
# AUTO-UPDATE CONFIGURATION
# =============================================================================

auto_update:
  # Master switch for automatic source code updates
  # When enabled, validated heals will update source files after tests pass
  enabled: false

  # Minimum confidence threshold for auto-updates (0.0 - 1.0)
  # Only heals with confidence >= this value will be auto-updated
  min_confidence: 0.85

  # Require the test to pass before applying updates
  # When true (recommended), heals are only applied after test validation
  require_test_pass: true

  # Create backup files before modifying source code
  # Backups are created with .bak extension
  backup_enabled: true

  # Directory for storing backup files
  # Relative to project root or absolute path
  backup_dir: .healer/backups

  # File patterns to exclude from auto-update
  # Uses glob patterns (** matches any directory depth)
  exclude_patterns:
    - "**/src/test/resources/**"
    - "**/*IT.java"
    - "**/generated/**"

  # Dry-run mode - show what would be updated without making changes
  # Useful for reviewing potential updates before enabling
  dry_run: false
```

#### Supported Locator Patterns

Auto-update supports the following locator patterns in your source code:

| Pattern | Example |
|---------|---------|
| `By.id()` | `By.id("login-btn")` |
| `By.xpath()` | `By.xpath("//button[@id='submit']")` |
| `By.cssSelector()` | `By.cssSelector(".login-form button")` |
| `By.name()` | `By.name("username")` |
| `By.className()` | `By.className("btn-primary")` |
| `By.linkText()` | `By.linkText("Sign In")` |
| `By.partialLinkText()` | `By.partialLinkText("Sign")` |
| `By.tagName()` | `By.tagName("button")` |
| `@FindBy(id=)` | `@FindBy(id = "login-btn")` |
| `@FindBy(xpath=)` | `@FindBy(xpath = "//button")` |
| `@FindBy(css=)` | `@FindBy(css = ".login-btn")` |

#### How Auto-Update Works

1. **Test runs** and encounters a broken locator
2. **Healing Engine** finds a working alternative with confidence score
3. **Test continues** using the healed locator
4. **Test passes** - this validates the heal was correct
5. **Source code updated** - the original locator is replaced with the healed one
6. **Backup created** - original file saved for rollback if needed

#### Rollback Options

If an auto-update causes issues, you have several rollback options:

```bash
# Using the CLI
healer patch rollback

# Manually restore from backup
cp .healer/backups/LoginTest.java.bak src/test/java/LoginTest.java

# Using git
git checkout -- src/test/java/LoginTest.java
```

#### Auto-Update Reports

When auto-updates are applied, a detailed HTML report is generated showing:
- Files modified
- Before/after locator values
- Confidence scores
- Backup file locations
- Rollback instructions

Reports are saved to the configured report output directory.

### Provider-Specific Configuration

#### OpenAI
```yaml
llm:
  provider: openai
  model: gpt-4o-mini  # or gpt-4, gpt-3.5-turbo
  api_key_env: OPENAI_API_KEY
```

#### Anthropic
```yaml
llm:
  provider: anthropic
  model: claude-3-haiku-20240307  # or claude-3-opus-20240229
  api_key_env: ANTHROPIC_API_KEY
```

#### Azure OpenAI
```yaml
healer:
  llm:
    provider: azure
    model: your-deployment-name                        # Your Azure deployment name
    base_url: https://your-resource.openai.azure.com   # Base URL only, NOT full path!
    api_key_env: AZURE_OPENAI_API_KEY
```

> **Important:** The `base_url` must be just the base URL (e.g., `https://your-resource.openai.azure.com`), NOT the full endpoint path like `https://...openai.azure.com/openai/deployments/gpt-4o/chat/completions`. The code constructs the full path automatically using your `model` (deployment name).

#### AWS Bedrock
```yaml
llm:
  provider: bedrock
  model: anthropic.claude-3-haiku-20240307-v1:0
  # Uses AWS credentials from environment or ~/.aws/credentials
```

#### Ollama (Local LLM)

Ollama allows you to run LLMs locally without any API keys or cloud costs. This is ideal for:
- Development and testing without API costs
- Air-gapped environments
- Privacy-sensitive applications
- Unlimited usage without rate limits

##### Installing Ollama

**Windows:**
```powershell
# Using winget (recommended)
winget install Ollama.Ollama

# Or download from: https://ollama.ai/download/windows
```

**macOS:**
```bash
# Using Homebrew
brew install ollama

# Or download from: https://ollama.ai/download/mac
```

**Linux:**
```bash
# One-line install script
curl -fsSL https://ollama.ai/install.sh | sh

# Or via package managers:
# Ubuntu/Debian
sudo apt install ollama

# Fedora
sudo dnf install ollama
```

##### Starting the Ollama Server

Ollama runs as a background service. Start it before running your tests:

```bash
# Start Ollama server (runs on port 11434 by default)
ollama serve

# Or run in background
ollama serve &

# On Windows, Ollama typically starts automatically after installation
# Check if it's running:
curl http://localhost:11434/api/tags
```

##### Pulling Models

Before using a model, you need to download it:

```bash
# Recommended models for Intent Healer:

# Llama 3.1 - Best overall performance (8B parameters)
ollama pull llama3.1

# Mistral - Good balance of speed and quality (7B)
ollama pull mistral

# CodeLlama - Optimized for code understanding (7B)
ollama pull codellama

# Phi-3 - Fast and lightweight (3.8B)
ollama pull phi3

# Gemma 2 - Google's efficient model (9B)
ollama pull gemma2

# List downloaded models
ollama list

# Remove a model
ollama rm <model-name>
```

**Model Selection Guide:**

| Model | Size | Speed | Quality | Best For |
|-------|------|-------|---------|----------|
| `llama3.1` | 8B | Medium | Excellent | Production use |
| `llama3.1:70b` | 70B | Slow | Best | Complex healing |
| `mistral` | 7B | Fast | Good | Daily development |
| `codellama` | 7B | Fast | Good | Code-heavy tests |
| `phi3` | 3.8B | Very Fast | Decent | Quick iterations |
| `gemma2` | 9B | Medium | Very Good | Balanced choice |

##### Configuration for Ollama

```yaml
# healer-config.yml
healer:
  mode: AUTO_SAFE
  enabled: true

llm:
  provider: ollama
  model: llama3.1              # or mistral, codellama, phi3, etc.
  base_url: http://localhost:11434
  timeout_seconds: 120         # Local models may need more time
  max_retries: 2
  temperature: 0.1             # Lower = more consistent results

  # Fallback to cloud if local is slow/unavailable
  fallback:
    - provider: openai
      model: gpt-4o-mini
      api_key_env: OPENAI_API_KEY
```

##### Environment Variables

```bash
# Override default Ollama endpoint
export OLLAMA_HOST=http://localhost:11434

# Override default model
export OLLAMA_MODEL=mistral

# For remote Ollama servers
export OLLAMA_HOST=http://your-server:11434
```

##### Verifying Ollama Setup

```bash
# Check if Ollama is running
curl http://localhost:11434/api/tags

# Test a model directly
ollama run llama3.1 "What is 2+2?"

# Check available models
ollama list

# View model info
ollama show llama3.1
```

##### Troubleshooting Ollama

**"Connection refused" error:**
```
LlmException: Connection refused to http://localhost:11434
```
Solution: Start the Ollama server with `ollama serve`

**"Model not found" error:**
```
Error: model 'llama3.1' not found
```
Solution: Pull the model first with `ollama pull llama3.1`

**Slow responses:**
- Try a smaller model (e.g., `phi3` instead of `llama3.1`)
- Increase `timeout_seconds` in config
- Ensure you have enough RAM (8GB+ recommended for 7B models)
- Use GPU acceleration if available

**Out of memory:**
```
Error: not enough memory
```
Solutions:
- Use a smaller model (`phi3` needs ~4GB RAM)
- Close other applications
- For larger models, ensure you have GPU with sufficient VRAM

##### Running Ollama on a Remote Server

For team environments, you can run Ollama on a central server:

```bash
# On the server - bind to all interfaces
OLLAMA_HOST=0.0.0.0:11434 ollama serve

# In healer-config.yml on client machines
llm:
  provider: ollama
  endpoint: http://your-ollama-server:11434
  model: llama3.1
```

##### GPU Acceleration

Ollama automatically uses GPU if available:
- **NVIDIA**: Install CUDA drivers
- **AMD**: Install ROCm (Linux only)
- **Apple Silicon**: Native Metal support (automatic)

Check GPU usage:
```bash
# NVIDIA
nvidia-smi

# Ollama will log GPU usage on startup
ollama serve
# Look for: "using CUDA" or "using Metal"
```

---

## Integration Guide

### Cucumber Integration

#### Step 1: Register the Plugin

```java
@CucumberOptions(
    features = "src/test/resources/features",
    glue = "com.example.steps",
    plugin = {
        "pretty",
        "html:build/cucumber-reports",
        "io.github.glaciousm.cucumber.HealerCucumberPlugin"  // Add this
    }
)
@RunWith(Cucumber.class)
public class RunCucumberTest {
}
```

#### Step 2: Set Up WebDriver in Steps

```java
public class BaseSteps {
    protected static HealingWebDriver driver;

    @Before
    public void setUp() {
        HealerTestConfig config = HealerTestConfig.getInstance();
        driver = config.createDriver();
    }

    @After
    public void tearDown() {
        if (driver != null) {
            driver.quit();
        }
    }
}
```

#### Step 3: Add Intent Annotations (Optional but Recommended)

```java
public class LoginSteps extends BaseSteps {

    @When("I enter username {string}")
    @Intent(
        action = "enter_username",
        description = "Enter username in the login form",
        healPolicy = HealPolicy.AUTO_SAFE
    )
    public void enterUsername(String username) {
        driver.findElement(By.id("username")).sendKeys(username);
    }

    @When("I click the login button")
    @Intent(
        action = "click_login",
        description = "Submit the login form",
        healPolicy = HealPolicy.AUTO_SAFE
    )
    @Invariant(check = NoErrorBannerCheck.class)  // Pre-action check
    @Outcome(check = UrlChangedCheck.class)       // Post-action validation
    public void clickLogin() {
        driver.findElement(By.xpath("//button[@type='submit']")).click();
    }
}
```

### JUnit 5 Integration

#### Step 1: Add Extension

```java
@ExtendWith(HealerExtension.class)
public class LoginTest {

    private WebDriver driver;  // Auto-wrapped by extension

    @BeforeEach
    void setUp() {
        driver = new ChromeDriver();
        driver.get("https://example.com/login");
    }

    @AfterEach
    void tearDown() {
        if (driver != null) {
            driver.quit();
        }
    }

    @Test
    @HealEnabled(intent = "Login with valid credentials")
    void testValidLogin() {
        // Healing is automatic - just write normal Selenium code
        driver.findElement(By.id("username")).sendKeys("user@test.com");
        driver.findElement(By.id("password")).sendKeys("password123");
        driver.findElement(By.cssSelector("button[type='submit']")).click();

        // Assertions
        assertTrue(driver.getCurrentUrl().contains("/dashboard"));
    }

    @Test
    @HealDisabled  // Explicitly disable healing for this test
    void testWithoutHealing() {
        // Standard Selenium - no healing
    }
}
```

### TestNG Integration

#### Step 1: Add Listener

**Via testng.xml:**
```xml
<!DOCTYPE suite SYSTEM "https://testng.org/testng-1.0.dtd">
<suite name="Test Suite">
    <listeners>
        <listener class-name="io.github.glaciousm.testng.HealerTestListener"/>
    </listeners>

    <test name="Login Tests">
        <classes>
            <class name="com.example.LoginTest"/>
        </classes>
    </test>
</suite>
```

**Or via annotation:**
```java
@Listeners(HealerTestListener.class)
public class LoginTest {
    private WebDriver driver;  // Auto-wrapped

    @BeforeMethod
    public void setUp() {
        driver = new ChromeDriver();
    }

    @Test
    public void testLogin() {
        driver.findElement(By.id("username")).sendKeys("test");
        // Healing happens automatically on element not found
    }
}
```

### Programmatic Integration

For custom setups or non-standard test frameworks:

```java
public class CustomIntegration {

    public static void main(String[] args) {
        // 1. Load configuration
        HealerConfig config = ConfigLoader.load();

        // 2. Create the healing engine
        HealingEngine engine = new HealingEngine(config);

        // 3. Configure LLM orchestrator
        LlmOrchestrator llm = new LlmOrchestrator();

        // 4. Wire up the engine
        engine.setSnapshotCapture(failure -> {
            // Capture UI snapshot
            return SnapshotBuilder.capture(driver);
        });

        engine.setLlmEvaluator((failure, snapshot) -> {
            // Call LLM for healing decision
            return llm.evaluateCandidates(failure, snapshot);
        });

        engine.setActionExecutor((action, element, data) -> {
            // Execute the healed action
            switch (action) {
                case CLICK -> element.click();
                case SEND_KEYS -> element.sendKeys(data);
                // etc.
            }
        });

        // 5. Create healing driver
        WebDriver rawDriver = new ChromeDriver();
        HealingWebDriver driver = new HealingWebDriver(rawDriver, engine, config);

        // 6. Use normally - healing is automatic
        driver.get("https://example.com");

        IntentContract intent = IntentContract.builder()
            .action("login")
            .description("Perform user login")
            .policy(HealPolicy.AUTO_SAFE)
            .build();

        driver.setCurrentIntent(intent, "Login step");

        try {
            driver.findElement(By.id("login-btn")).click();
        } finally {
            driver.clearCurrentIntent();
            driver.quit();
        }
    }
}
```

---

## CLI Reference

Install the CLI tool or run via Maven:

```bash
# Via Maven
mvn -pl healer-cli exec:java -Dexec.args="<command>"

# Or if installed globally
healer <command>
```

### Configuration Commands

```bash
# Show current configuration
healer config show

# Validate configuration file
healer config validate

# Create default configuration file
healer config init
healer config init ./custom/path/config.yml

# Show configuration file search locations
healer config where
```

### Cache Commands

```bash
# Show cache statistics
healer cache stats

# Clear the cache (requires confirmation)
healer cache clear
healer cache clear --force

# Warm up cache from existing reports
healer cache warmup
healer cache warmup ./path/to/reports

# Export cache to file
healer cache export
healer cache export ./backup/cache.json

# Import cache from file
healer cache import ./backup/cache.json
```

### Report Commands

```bash
# Show summary of recent healing activity
healer report summary
healer report summary ./custom/reports/dir

# List recent heals
healer report list
healer report list ./reports 50  # Show 50 entries

# Generate report from data
healer report generate ./input ./output html
healer report generate ./input ./output json
```

### Utility Commands

```bash
# Show version
healer version

# Show help
healer help
healer config help
healer cache help
```

---

## IDE Plugins

### IntelliJ IDEA Plugin

#### Installation

**From Marketplace (when available):**

1. Open IntelliJ IDEA
2. Go to **Settings** → **Plugins** → **Marketplace**
3. Search for "Intent Healer"
4. Click **Install** and restart IDE

**From Source:**

The IntelliJ plugin is built separately using Gradle:

```bash
cd healer-intellij
./gradlew buildPlugin
```

Then install the plugin ZIP from `build/distributions/` via **Settings** → **Plugins** → **⚙️** → **Install Plugin from Disk...**

For more details, see [healer-intellij/README.md](../healer-intellij/README.md).

#### Features

| Feature | Access |
|---------|--------|
| Dashboard | View → Tool Windows → Intent Healer |
| Settings | Settings → Tools → Intent Healer |
| Heal History | Tools → Intent Healer → View Heal History |
| Refresh Cache | Tools → Intent Healer → Refresh Cache |
| Clear Cache | Tools → Intent Healer → Clear Cache |
| Suggest Locator | Right-click in editor → Suggest Stable Locator |

#### Configuration

1. Go to **Settings** → **Tools** → **Intent Healer**
2. Configure:
   - **Healer Mode**: OFF / SUGGEST / AUTO_SAFE / AUTO_ALL
   - **API Key**: Your LLM provider API key
   - **Cache Directory**: Location for heal cache
   - **Enable Notifications**: Show heal notifications
   - **Max History Entries**: Number of entries to keep
   - **Persist History**: Save history between sessions

#### Using the Dashboard

1. Open the **Intent Healer** tool window (right sidebar)
2. **Dashboard Tab**: View real-time healing activity
3. **History Tab**: Browse past heals
   - Double-click to view details
   - Use **Accept/Reject/Blacklist** buttons
4. **Stability Tab**: View locator stability scores

### VS Code Extension

#### Installation

1. Open VS Code
2. Go to Extensions (Ctrl+Shift+X)
3. Search for "Intent Healer"
4. Click **Install**

#### Features

| Feature | Access |
|---------|--------|
| Views | Activity Bar → Intent Healer icon |
| Commands | Command Palette (Ctrl+Shift+P) → "Intent Healer" |
| Settings | Settings → Extensions → Intent Healer |

#### Views

**Heal History View**
- Browse healing events
- Expand entries for details
- Actions: Accept, Reject, Blacklist
- Refresh button

**Trust Level View**
- Current trust level and score
- Trust by locator strategy
- Trust by element type

**Locator Stability View**
- Stability scores for locators
- Recommendations for unstable locators

#### Commands

| Command | Description |
|---------|-------------|
| `Intent Healer: Refresh History` | Reload heal history |
| `Intent Healer: Accept Heal` | Accept selected heal |
| `Intent Healer: Reject Heal` | Reject selected heal |
| `Intent Healer: Blacklist Heal` | Blacklist heal pattern |
| `Intent Healer: Open Dashboard` | Open full dashboard |
| `Intent Healer: Export Report` | Export healing report |
| `Intent Healer: Clear Cache` | Clear heal cache |

#### Settings

```json
{
    "intentHealer.cacheDirectory": ".intent-healer",
    "intentHealer.autoRefresh": true,
    "intentHealer.refreshInterval": 30,
    "intentHealer.showNotifications": true,
    "intentHealer.confidenceWarningThreshold": 0.75
}
```

---

## Healing Modes & Policies

### Healing Modes

| Mode | Description | When to Use |
|------|-------------|-------------|
| `OFF` | Healing completely disabled | Production, debugging |
| `SUGGEST` | Log suggestions, don't auto-heal | Initial evaluation |
| `AUTO_SAFE` | Auto-heal safe actions only | Recommended default |
| `AUTO_ALL` | Auto-heal all healable failures | Mature, trusted setup |

### Heal Policies (Per-Step)

| Policy | Description |
|--------|-------------|
| `OFF` | Never heal this step |
| `SUGGEST` | Suggest only, don't auto-heal |
| `AUTO_SAFE` | Auto-heal if action is safe |
| `AUTO_ALL` | Auto-heal regardless of action type |

### What's Considered "Safe"?

**Safe Actions (AUTO_SAFE):**
- Reading element text
- Getting element attributes
- Clicking non-destructive buttons
- Entering text in input fields
- Navigation within the app

**Unsafe Actions (require AUTO_ALL):**
- Clicking delete/remove buttons
- Form submissions to destructive endpoints
- Actions matching forbidden keywords
- Actions on admin/settings pages

### Healable vs Non-Healable Failures

**Healable:**
- `NoSuchElementException` - Element not found
- `StaleElementReferenceException` - Element became stale
- `ElementClickInterceptedException` - Click blocked
- `ElementNotInteractableException` - Can't interact
- `TimeoutException` - Element wait timeout

**Not Healable:**
- `AssertionError` - Test assertions
- `WebDriverException` - Browser/driver issues
- Network errors
- JavaScript errors

---

## Trust Levels

The framework uses a progressive trust system that increases automation as healing proves reliable.

### Trust Level Progression

| Level | Name | Description | Auto-Heal |
|-------|------|-------------|-----------|
| L0 | SHADOW | Learning mode, no auto-heal | No |
| L1 | SUGGEST | Suggestions logged for review | No |
| L2 | CONFIRM | Requires human confirmation | Ask |
| L3 | AUTO_SAFE | Auto-heal safe actions | Safe only |
| L4 | SILENT | Full auto-healing | Yes |

### Progression Criteria

**L0 → L1 (Shadow → Suggest)**
- 5+ successful shadow heals
- 0 rejections

**L1 → L2 (Suggest → Confirm)**
- 10+ accepted suggestions
- <5% rejection rate

**L2 → L3 (Confirm → Auto-Safe)**
- 20+ confirmed heals
- <2% false positive rate
- 7+ days of data

**L3 → L4 (Auto-Safe → Silent)**
- 50+ successful auto-heals
- <1% false positive rate
- 30+ days of data

### Demotion Triggers

- 3 consecutive false positives → Drop 1 level
- >5% false positive rate in 7 days → Drop to L1
- Manual demotion via CLI/IDE

---

## Reports & Monitoring

### Report Types

**JSON Report** (`healer-report-{timestamp}.json`)
```json
{
  "summary": {
    "totalAttempts": 15,
    "successes": 12,
    "refusals": 2,
    "failures": 1,
    "totalCost": 0.0234
  },
  "events": [
    {
      "id": "heal-123",
      "timestamp": "2024-01-15T10:30:00Z",
      "stepText": "I click the login button",
      "originalLocator": "By.id: login-btn",
      "healedLocator": "By.xpath: //button[@data-testid='login']",
      "confidence": 0.92,
      "reasoning": "Found button with matching test ID...",
      "outcome": "SUCCESS"
    }
  ]
}
```

**HTML Report** (`healer-report-{timestamp}.html`)
- Interactive, styled report
- Collapsible event entries
- Screenshots inline
- Filter by outcome
- Search functionality

### Viewing Reports

```bash
# Generate summary
healer report summary

# List recent heals
healer report list

# Open HTML report in browser
open build/healer-reports/healer-report-*.html
```

### Monitoring Metrics

**Key Metrics to Track:**
- **Heal Success Rate**: % of heals that worked
- **False Positive Rate**: % of heals that were wrong
- **LLM Cost**: Total spend on LLM calls
- **Latency**: Time taken for healing
- **Cache Hit Rate**: % of heals served from cache

**Circuit Breaker States:**
- **CLOSED**: Normal operation
- **OPEN**: Healing disabled (too many failures or cost exceeded)
- **HALF_OPEN**: Testing if healing should resume

---

## Troubleshooting

### Common Issues

#### "No API key found"
```
Error: LLM API key not configured
```
**Solution:** Set the environment variable:
```bash
export OPENAI_API_KEY="sk-your-key"
```

#### "Confidence too low"
```
Heal refused: confidence 0.65 below threshold 0.80
```
**Solution:** Lower `confidence_threshold` in config, or improve locator specificity.

#### "Circuit breaker open"
```
Healing disabled: circuit breaker open
```
**Solution:** Wait for cooldown, or check:
- Daily cost limit not exceeded
- False positive rate acceptable
- Check logs for consecutive failures

#### "Max heals per scenario exceeded"
```
Healing stopped: reached max heals (5) for scenario
```
**Solution:** Increase `max_heals_per_scenario` or fix underlying locator issues.

#### "Forbidden keyword detected"
```
Heal refused: element contains forbidden keyword 'delete'
```
**Solution:** Remove keyword from `forbidden_keywords` if safe, or use `HealPolicy.AUTO_ALL`.

### LLM Provider Issues

#### Connection timeout
```
LlmException: Connection timed out
```
**Solutions:**
- Increase `timeout_seconds` in LLM config (default: 30)
- Check network connectivity and firewall rules
- Verify the API endpoint is reachable
- For Ollama: ensure the local server is running (`ollama serve`)

#### Rate limiting (HTTP 429)
```
OpenAI API error: 429 - Rate limit exceeded
```
**Solutions:**
- Enable caching to reduce API calls (`cache.enabled: true`)
- Configure fallback providers for automatic failover
- Reduce `max_requests_per_test_run` if running parallel tests
- Contact your LLM provider to increase rate limits

#### Invalid API response
```
Failed to parse LLM response: Invalid JSON structure
```
**Solutions:**
- Ensure you're using a supported model version
- Check that `max_tokens_per_request` is sufficient (minimum 500 recommended)
- Enable `include_llm_prompts: true` to debug the actual prompts being sent

### Selenium/WebDriver Issues

#### Stale element after healing
```
StaleElementReferenceException after heal
```
**Solutions:**
- Enable `@Outcome` validation to verify healed element
- Add explicit waits after dynamic page updates
- Check for iframe/shadow DOM context switches

#### Element not interactable after healing
```
ElementNotInteractableException: element not visible
```
**Solutions:**
- Verify the healed locator targets a visible element
- Add `snapshot.include_hidden: false` to exclude hidden elements
- Check for overlaying elements (modals, popups)

#### Slow healing performance
```
Healing taking >10 seconds per element
```
**Solutions:**
- Enable caching for repeated heals (`cache.enabled: true`)
- Reduce `snapshot.max_elements` to limit DOM capture (default: 500)
- Use a faster LLM model (e.g., `gpt-4o-mini` instead of `gpt-4`)
- Configure `snapshot.capture_screenshot: false` if not needed

### Configuration Issues

#### Configuration file not found
```
Warning: No healer-config.yml found, using defaults
```
**Solutions:**
- Create `healer-config.yml` in project root or `src/test/resources/`
- Set `HEALER_CONFIG` environment variable to custom path
- Run `healer config init` to create a template

#### Invalid configuration values
```
ConfigurationException: Invalid confidence_threshold: 1.5
```
**Solutions:**
- Run `healer config validate` to check for errors
- Ensure numeric values are in valid ranges:
  - `confidence_threshold`: 0.0 - 1.0
  - `temperature`: 0.0 - 2.0
  - `timeout_seconds`: 1 - 300

### Cache Issues

#### Cache not persisting between runs
```
Cache empty on test restart
```
**Solutions:**
- Set `cache.storage: FILE` for persistent storage
- Verify `cache.file_path` directory is writable
- Check `cache.persistence_enabled: true`

#### Cache returning stale heals
```
Cached heal no longer valid
```
**Solutions:**
- Clear cache: `healer cache clear --force`
- Reduce `cache.ttl_hours` for faster expiration
- Set `cache.min_confidence_to_cache` higher to only cache high-quality heals

### Thread Safety Issues

#### Concurrent test failures
```
Multiple tests failing with inconsistent heals
```
**Solutions:**
- Intent Healer is thread-safe by default
- Each `HealingWebDriver` instance maintains its own context
- Avoid sharing driver instances across test threads
- Use `@Execution(ExecutionMode.SAME_THREAD)` in JUnit if needed

### Debug Mode

Enable detailed logging:

```yaml
# In healer-config.yml
report:
  include_llm_prompts: true
  include_dom_snapshots: true
```

Or via environment:
```bash
export HEALER_DEBUG=true
mvn test
```

View detailed logs with SLF4J:
```xml
<!-- In logback.xml -->
<logger name="io.github.glaciousm" level="DEBUG"/>
```

### Getting Help

1. Check logs in `target/healer-reports/`
2. Review heal history in IDE plugin
3. Run `healer config validate` to check configuration
4. Enable debug mode for detailed diagnostics
5. Check the [GitHub Issues](https://github.io/github/glaciousm/intent-healer/issues) for known problems
6. File a bug report with:
   - Healer configuration (with API keys redacted)
   - Error message and stack trace
   - Steps to reproduce

---

## Best Practices

### Configuration

1. **Start Conservative**: Begin with `mode: SUGGEST` to evaluate before auto-healing
2. **Set Cost Limits**: Always configure `max_cost_per_run_usd` and `daily_cost_limit_usd`
3. **Use Fallback Providers**: Configure multiple LLM providers for reliability
4. **Enable Caching**: Dramatically reduces costs and latency

### Test Design

1. **Use Descriptive Intents**: Clear `@Intent` annotations help LLM understand context
2. **Prefer Stable Locators**: Use `data-testid`, `aria-label` over brittle XPaths
3. **Add Invariants**: Use `@Invariant` to prevent healing when errors are present
4. **Validate Outcomes**: Use `@Outcome` to verify healing worked correctly

### Operations

1. **Review Heals Regularly**: Accept/reject heals to improve trust level
2. **Monitor Costs**: Check daily LLM spend in reports
3. **Blacklist Bad Patterns**: Permanently block incorrect heal patterns
4. **Update Locators**: Use heal suggestions to update source locators

### Security

1. **Never Commit API Keys**: Use environment variables
2. **Set Forbidden Keywords**: Block destructive actions in your language
3. **Configure Forbidden URLs**: Protect admin/sensitive pages
4. **Review Before AUTO_ALL**: Only use full auto-heal with established trust

---

## Appendix: Quick Reference

### Environment Variables

| Variable | Description |
|----------|-------------|
| `OPENAI_API_KEY` | OpenAI API key |
| `ANTHROPIC_API_KEY` | Anthropic API key |
| `AZURE_OPENAI_API_KEY` | Azure OpenAI API key |
| `AZURE_OPENAI_ENDPOINT` | Azure OpenAI endpoint URL |
| `AWS_ACCESS_KEY_ID` | AWS access key (for Bedrock) |
| `AWS_SECRET_ACCESS_KEY` | AWS secret key (for Bedrock) |
| `HEALER_CONFIG` | Custom config file path |
| `HEALER_DEBUG` | Enable debug logging |

### Annotations

| Annotation | Purpose |
|------------|---------|
| `@Intent` | Describe step intent for healing context |
| `@Invariant` | Pre-action safety check |
| `@Outcome` | Post-action validation |
| `@HealEnabled` | Enable healing (JUnit) |
| `@HealDisabled` | Disable healing (JUnit) |

### CLI Quick Reference

```bash
healer config show          # View config
healer config validate      # Validate config
healer config init          # Create config
healer cache stats          # Cache info
healer cache clear --force  # Clear cache
healer report summary       # View summary
healer report list          # List heals
healer version              # Version info
healer help                 # Help
```

---

*Intent Healer v1.0 - LLM-Powered Self-Healing for Selenium Tests*
